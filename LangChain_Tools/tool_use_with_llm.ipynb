{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66431f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e02c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model setup successfull...\n"
     ]
    }
   ],
   "source": [
    "# Model setup \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "chat_model_name = os.environ.get(\"GOOGLE_CHAT_MODEL\")\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(model = chat_model_name)\n",
    "\n",
    "print(\"Chat model setup successfull...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222113b0",
   "metadata": {},
   "source": [
    "# create tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e47d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool\n",
    "def mul( a : int, b : int) -> int: \n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bb8bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(mul.invoke({'a':3,'b':3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865cc1b",
   "metadata": {},
   "source": [
    "# Tool Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Binding\n",
    "llm_with_tools = chat_model.bind_tools([mul])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ac3d8",
   "metadata": {},
   "source": [
    "# Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a037c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--b9947f03-fbd1-4c5e-b253-9b2a7539b140-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e4c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'mul', 'arguments': '{\"a\": 3.0, \"b\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--f00625d4-ea28-4658-b709-02d9060f4a0f-0', tool_calls=[{'name': 'mul', 'args': {'a': 3.0, 'b': 10.0}, 'id': '4639fe05-7668-452a-a9e7-1e69346f2759', 'type': 'tool_call'}], usage_metadata={'input_tokens': 18, 'output_tokens': 5, 'total_tokens': 23, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"Multiply 3 * 10\").tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "689acee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mul',\n",
       " 'args': {'a': 3.0, 'b': 10.0},\n",
       " 'id': '82e16c3d-7fc6-4701-84e4-cd2f8a0f8858',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"Multiply 3 * 10\").tool_calls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b85da",
   "metadata": {},
   "source": [
    "# Tool Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5920657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_output = llm_with_tools.invoke(\"Multiply 3 * 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1142a825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mul',\n",
       " 'args': {'a': 3.0, 'b': 10.0},\n",
       " 'id': '287a1196-7551-49b4-9e89-105611bfab4a',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_output.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859a006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul.invoke({'a': 3.0, 'b': 10.0}) # Only with arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae449707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='30', name='mul', tool_call_id='287a1196-7551-49b4-9e89-105611bfab4a')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With all all the information\n",
    "\n",
    "mul.invoke({'name': 'mul',\n",
    " 'args': {'a': 3.0, 'b': 10.0},\n",
    " 'id': '287a1196-7551-49b4-9e89-105611bfab4a',\n",
    " 'type': 'tool_call'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e675c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='30', name='mul', tool_call_id='287a1196-7551-49b4-9e89-105611bfab4a')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul.invoke(call_output.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d355f2e",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "562490d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,AIMessage,ToolMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a558312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Message: [HumanMessage(content='Can you multiply 3 with 20', additional_kwargs={}, response_metadata={})]\n",
      "LLM Response Tool Call : content='' additional_kwargs={'function_call': {'name': 'mul', 'arguments': '{\"a\": 3.0, \"b\": 20.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--d61d0996-3cbc-4579-b858-4a0c2385edd3-0' tool_calls=[{'name': 'mul', 'args': {'a': 3.0, 'b': 20.0}, 'id': '4719d4f8-9030-4ff8-9fda-45c5aa57c9db', 'type': 'tool_call'}] usage_metadata={'input_tokens': 20, 'output_tokens': 5, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}}\n",
      "Message After Tool Output: content='60' name='mul' tool_call_id='4719d4f8-9030-4ff8-9fda-45c5aa57c9db'\n",
      "Final Response : The result of multiplying 3 with 20 is 60.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Human Message\n",
    "query = HumanMessage(\"Can you multiply 3 with 20\")\n",
    "\n",
    "messages = [query]\n",
    "\n",
    "print(f\"Initial Message: {messages}\")\n",
    "\n",
    "# Step 2: First LLM call to get the tool\n",
    "\n",
    "response = llm_with_tools.invoke(messages)\n",
    "\n",
    "messages.append(response)\n",
    "\n",
    "print(f\"LLM Response Tool Call : {response}\")\n",
    "\n",
    "# Step 3: Execute the tool \n",
    "# tool_call = response.tool_calls[0]\n",
    "\n",
    "# tool_output = mul.invoke(tool_call['args'])\n",
    "\n",
    "# print(f\"Message After Tool Output: {tool_output}\")\n",
    "\n",
    "# messages.append(ToolMessage(content=str(tool_output), tool_call_id=tool_call['id']))\n",
    "\n",
    "tool_output = mul.invoke(response.tool_calls[0])\n",
    "\n",
    "messages.append(tool_output)\n",
    "\n",
    "print(f\"Message After Tool Output: {tool_output}\")\n",
    "\n",
    "# Step 4: Send the tool's output back to the model\n",
    "\n",
    "final_output = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(f\"Final Response : {final_output.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
